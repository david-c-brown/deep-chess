{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import numpy as np\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "import concurrent.futures\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "from functools import lru_cache\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tensorflow.keras import layers, mixed_precision\n",
    "from tensorflow.keras.losses import Huber\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Board and Input Conversion Functions\n",
    "def board_to_input(board, history=1):\n",
    "    pieces = {\n",
    "        \"P\": 0,\n",
    "        \"N\": 1,\n",
    "        \"B\": 2,\n",
    "        \"R\": 3,\n",
    "        \"Q\": 4,\n",
    "        \"K\": 5,\n",
    "        \"p\": 6,\n",
    "        \"n\": 7,\n",
    "        \"b\": 8,\n",
    "        \"r\": 9,\n",
    "        \"q\": 10,\n",
    "        \"k\": 11,\n",
    "    }\n",
    "\n",
    "    input_tensor = np.zeros((1, 8, 8, 12 * history), dtype=np.float32)\n",
    "\n",
    "    board_states = [board]\n",
    "    for _ in range(history - 1):\n",
    "        if len(board.move_stack) > 0:\n",
    "            move = board.pop()\n",
    "            new_board = board.copy()\n",
    "            board.push(move)\n",
    "            board_states.insert(0, new_board)\n",
    "        else:\n",
    "            board_states.insert(0, None)\n",
    "\n",
    "    for h, state in enumerate(board_states):\n",
    "        if state is not None:\n",
    "            for i in range(8):\n",
    "                for j in range(8):\n",
    "                    piece = state.piece_at(chess.square(i, j))\n",
    "                    if piece:\n",
    "                        input_tensor[0, i, j, pieces[str(piece)] + 12 * h] = 1\n",
    "\n",
    "    return input_tensor\n",
    "\n",
    "def moves_to_array(moves):\n",
    "    move_array = np.zeros(4672)\n",
    "    for move in moves:\n",
    "        move_idx = move.from_square * 73 + move.to_square\n",
    "        move_array[move_idx] = 1\n",
    "    return move_array\n",
    "\n",
    "def array_to_move(board, move_array):\n",
    "    legal_moves = list(board.legal_moves)\n",
    "    legal_move_probs = np.zeros(len(legal_moves))\n",
    "    for i, move in enumerate(legal_moves):\n",
    "        move_idx = move.from_square * 73 + move.to_square\n",
    "        legal_move_probs[i] = move_array[move_idx]\n",
    "    best_move_idx = np.argmax(legal_move_probs)\n",
    "    return legal_moves[best_move_idx] if legal_moves else None\n",
    "\n",
    "# Evaluation and Backpropagation Functions\n",
    "def material_balance(board):\n",
    "    piece_values = {\n",
    "        'P': 1,\n",
    "        'N': 3,\n",
    "        'B': 3,\n",
    "        'R': 5,\n",
    "        'Q': 9,\n",
    "        'K': 0,\n",
    "        'p': -1,\n",
    "        'n': -3,\n",
    "        'b': -3,\n",
    "        'r': -5,\n",
    "        'q': -9,\n",
    "        'k': 0,\n",
    "    }\n",
    "\n",
    "    balance = 0\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            balance += piece_values[str(piece)]\n",
    "\n",
    "    return balance\n",
    "\n",
    "def backpropagate(node, value):\n",
    "    while node is not None:\n",
    "        node.update(value)\n",
    "        node = node.parent\n",
    "        value = -value\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def cached_evaluate_board(board_fen):\n",
    "    board = chess.Board(board_fen)\n",
    "    return material_balance(board)\n",
    "\n",
    "@tf.function(reduce_retracing=True)  \n",
    "def model_predict(chess_model, board_input):\n",
    "    board_input = tf.convert_to_tensor(board_input, dtype=tf.float32) \n",
    "    return chess_model(board_input) \n",
    "\n",
    "def evaluate(self, board):\n",
    "    board_input = board_to_input(board).reshape(1, 8, 8, 12)\n",
    "    move_probs, value_estimate = model_predict(self, board_input)\n",
    "    return value_estimate.numpy().flatten()[0]\n",
    "\n",
    "board = chess.Board()\n",
    "input_tensor = board_to_input(board)\n",
    "print(input_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCTS Functions and Classes\n",
    "class MCTSNode:\n",
    "    def __init__(self, board, parent=None, move=None, prior=0):\n",
    "        self.board = board\n",
    "        self.parent = parent\n",
    "        self.move = move\n",
    "        self.children = []\n",
    "        self.visits = 0\n",
    "        self.value = 0\n",
    "        self.prior = prior\n",
    "        self.eval_value = self.evaluate_board()\n",
    "\n",
    "    def add_child(self, child_node):\n",
    "        self.children.append(child_node)\n",
    "\n",
    "    def update(self, value):\n",
    "        self.visits += 1\n",
    "        self.value += value\n",
    "\n",
    "    def expand_children_parallel(self, chess_model, num_threads=4):\n",
    "        legal_moves = list(self.board.legal_moves)\n",
    "        if len(legal_moves) == 0:\n",
    "            return\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "            futures = [executor.submit(self._expand_child, move, chess_model) for move in legal_moves]\n",
    "\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                child = future.result()\n",
    "                if child is not None:\n",
    "                    self.children.append(child)\n",
    "\n",
    "    def _expand_child(self, move, chess_model):\n",
    "      child_board = self.board.copy()\n",
    "      child_board.push(move)\n",
    "      child_node = MCTSNode(child_board, self, move)\n",
    "      child_node.evaluate(chess_model)\n",
    "      return child_node\n",
    "\n",
    "\n",
    "    def fully_expanded(self):\n",
    "        return len(self.children) == len(list(self.board.legal_moves))\n",
    "\n",
    "    def evaluate_board(self):\n",
    "        return material_balance(self.board)\n",
    "\n",
    "    def select_child(self, temperature):\n",
    "        \"\"\"\n",
    "        Select the child node with the highest UCB (Upper Confidence Bound) score.\n",
    "        \"\"\"\n",
    "        ucb_scores = [\n",
    "            (child.additional_rewards / (child.num_visits + 1e-10) +\n",
    "             math.sqrt(2 * math.log(self.num_visits + 1e-10) / (child.num_visits + 1e-10)))\n",
    "            for child in self.children\n",
    "        ]\n",
    "\n",
    "        if temperature == 0:\n",
    "            best_child_index = ucb_scores.index(max(ucb_scores))\n",
    "        else:\n",
    "            ucb_scores = [x**(1/temperature) for x in ucb_scores]\n",
    "            total_score = sum(ucb_scores)\n",
    "            probabilities = [x / total_score for x in ucb_scores]\n",
    "            best_child_index = np.random.choice(len(self.children), p=probabilities)\n",
    "\n",
    "        return self.children[best_child_index]\n",
    "\n",
    "    def additional_rewards(self, child_node):\n",
    "      rewards = 0\n",
    "      from_square = child_node.move.from_square\n",
    "\n",
    "      # Reward checkmate\n",
    "      if child_node.board.is_checkmate():\n",
    "          rewards += 100\n",
    "\n",
    "      # Reward capturing material\n",
    "      if child_node.board.is_capture(child_node.move):\n",
    "          material_value = material_balance(child_node.board)\n",
    "          if child_node.board.turn:  # White's turn\n",
    "              rewards += material_value\n",
    "          else:  # Black's turn\n",
    "              rewards += material_value  # Increase reward for black captures\n",
    "\n",
    "      # Reward putting king in check\n",
    "      if child_node.board.is_check():\n",
    "          rewards += 0.5\n",
    "\n",
    "      return rewards\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return len(self.children) == 0\n",
    "\n",
    "    def evaluate(self, chess_model):\n",
    "        self.visits += 1\n",
    "        self.value = chess_model.evaluate(self.board)\n",
    "\n",
    "    def best_child(self, c_param=1, eval_weight=0, temperature=1, noise=0, last_move=None):\n",
    "        if self.children == []:\n",
    "            return None\n",
    "\n",
    "        choices_weights = [\n",
    "            ((c.value / (c.visits + 1e-8) + c_param * (c.prior + np.random.randn() * noise) * np.sqrt(self.visits) / (1 + c.visits) + eval_weight * c.eval_value) / temperature)\n",
    "            + self.additional_rewards(c)\n",
    "            for c in self.children\n",
    "        ]\n",
    "\n",
    "        if last_move:\n",
    "            for i, c in enumerate(self.children):\n",
    "                if c.move == last_move:\n",
    "                    choices_weights[i] -= 100\n",
    "        return self.children[np.argmax(choices_weights)]\n",
    "\n",
    "class OptimizedMCTSNode(MCTSNode):\n",
    "    def evaluate_board(self):\n",
    "        return cached_evaluate_board(self.board.fen())\n",
    "\n",
    "def expand(node, chess_model):\n",
    "    board_input = board_to_input(node.board).reshape(1, 8, 8, 12)\n",
    "    move_probs, value_estimate = model_predict(chess_model, board_input)\n",
    "    move_probs = move_probs.numpy().flatten()\n",
    "\n",
    "    legal_moves = list(node.board.legal_moves)\n",
    "    for move in legal_moves:\n",
    "        new_board = node.board.copy()\n",
    "        new_board.push(move)\n",
    "        move_idx = move.from_square * 73 + move.to_square\n",
    "        prior = move_probs[move_idx]\n",
    "        child_node = MCTSNode(new_board, parent=node, move=move, prior=prior)\n",
    "        node.add_child(child_node)\n",
    "\n",
    "    return node.children[np.random.choice(len(node.children))]\n",
    "\n",
    "def mcts(board, chess_model, num_simulations, temperature=1.0, noise=0.0, parallel_sims=True):\n",
    "    root = MCTSNode(board, chess_model)\n",
    "\n",
    "    if not parallel_sims:\n",
    "        for _ in range(num_simulations):\n",
    "            current_board = board.copy()\n",
    "            node = root\n",
    "            while not node.is_leaf():\n",
    "                node = node.select_child(temperature)\n",
    "                current_board.push(node.move)\n",
    "            if not current_board.is_game_over():\n",
    "                node.expand_children(chess_model)\n",
    "    else:\n",
    "        def simulate(root):\n",
    "            current_board = board.copy()\n",
    "            node = root\n",
    "            while not node.is_leaf():\n",
    "                node = node.select_child(temperature)\n",
    "                current_board.push(node.move)\n",
    "            if not current_board.is_game_over():\n",
    "                node.expand_children_parallel(chess_model)\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=num_simulations) as executor:\n",
    "            executor.map(simulate, [root]*num_simulations)\n",
    "\n",
    "    return root.best_child().move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chess Model and Training Functions\n",
    "def residual_block(inputs, num_filters, kernel_size=(3, 3)):\n",
    "    x = layers.Conv2D(num_filters, kernel_size, padding=\"same\", activation=None)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(num_filters, kernel_size, padding=\"same\", activation=None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([inputs, x])\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_chess_model(num_res_blocks=19, num_filters=256):\n",
    "    input_shape = (8, 8, 12)\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape, dtype=tf.float16)\n",
    "    x = layers.Conv2D(num_filters, kernel_size=(3, 3), padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    for _ in range(num_res_blocks):\n",
    "        x = residual_block(x, num_filters)\n",
    "\n",
    "    # Policy head\n",
    "    policy = layers.Conv2D(2, kernel_size=(1, 1), padding=\"same\", activation=\"relu\")(x)\n",
    "    policy = layers.BatchNormalization()(policy)\n",
    "    policy = layers.Flatten()(policy)\n",
    "    policy = layers.Dense(4672, activation=\"softmax\")(policy)\n",
    "\n",
    "    # Value head\n",
    "    value = layers.Conv2D(1, kernel_size=(1, 1), padding=\"same\", activation=\"relu\")(x)\n",
    "    value = layers.BatchNormalization()(value)\n",
    "    value = layers.Flatten()(value)\n",
    "    value = layers.Dense(1, activation=\"tanh\")(value)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=[policy, value])\n",
    "\n",
    "    def evaluate(self, board):\n",
    "        board_input = board_to_input(board).reshape(1, 8, 8, 12)\n",
    "        move_probs, value_estimate = model_predict(self, board_input)\n",
    "        return value_estimate.numpy().flatten()[0]\n",
    "\n",
    "    model.evaluate = evaluate.__get__(model)\n",
    "    return model\n",
    "\n",
    "def compute_advantages(rewards, values, gamma=0.99, lambda_=0.95):\n",
    "    advantages = np.zeros_like(rewards)\n",
    "    gae = 0\n",
    "    for t in reversed(range(len(rewards))):\n",
    "        delta = rewards[t] + gamma * values[t + 1] - values[t]\n",
    "        gae = delta + gamma * lambda_ * gae\n",
    "        advantages[t] = gae\n",
    "    return advantages\n",
    "\n",
    "def ppo_loss_fn(advantages, old_probs, actions, logits, values, clip_epsilon=0.2, value_loss_coeff=0.5, entropy_coeff=0.01):\n",
    "    prob_ratio = tf.exp(tf.nn.log_softmax(logits) - tf.stop_gradient(tf.nn.log_softmax(old_probs)))\n",
    "    prob_ratio = tf.reduce_sum(prob_ratio * actions, axis=-1)\n",
    "    clipped_prob_ratio = tf.clip_by_value(prob_ratio, 1 - clip_epsilon, 1 + clip_epsilon)\n",
    "    surrogate_loss = -tf.reduce_mean(tf.minimum(prob_ratio * advantages, clipped_prob_ratio * advantages))\n",
    "\n",
    "    value_loss = Huber()(values, old_values)\n",
    "\n",
    "    entropy_loss = -tf.reduce_mean(tf.reduce_sum(tf.nn.softmax(logits) * tf.nn.log_softmax(logits), axis=-1))\n",
    "\n",
    "    total_loss = surrogate_loss + value_loss_coeff * value_loss - entropy_coeff * entropy_loss\n",
    "    return total_loss\n",
    "\n",
    "chess_model = create_chess_model()\n",
    "chess_model.summary()\n",
    "chess_model.evaluate = evaluate.__get__(chess_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate models for black and white players\n",
    "white_chess_model = create_chess_model()\n",
    "black_chess_model = create_chess_model()\n",
    "\n",
    "white_weights_file = \"weights/white_chess_model_weights.h5\"\n",
    "black_weights_file = \"weights/black_chess_model_weights.h5\"\n",
    "\n",
    "try:\n",
    "    white_chess_model.load_weights(white_weights_file)\n",
    "    black_chess_model.load_weights(black_weights_file)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "optimizer = 'adam'\n",
    "loss = 'categorical_crossentropy'\n",
    "\n",
    "white_chess_model.compile(optimizer=optimizer, loss=loss)\n",
    "black_chess_model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "def play_game(game_number, total_games, white_chess_model, black_chess_model, num_simulations=100, verbose=False, time_per_move=2):\n",
    "    board = chess.Board()\n",
    "\n",
    "    while not board.is_game_over():\n",
    "        if verbose:\n",
    "            clear_output(wait = True)\n",
    "            print(f\"\\nGame {game_number + 1} out of {total_games}\")\n",
    "            print(board)\n",
    "\n",
    "        if board.turn:  # White's turn\n",
    "            move = mcts(board, white_chess_model, num_simulations=num_simulations)\n",
    "        else:  # Black's turn\n",
    "            move = mcts(board, black_chess_model, num_simulations=num_simulations)\n",
    "\n",
    "        if verbose:\n",
    "            print(move)\n",
    "            time.sleep(time_per_move)\n",
    "\n",
    "        board.push(move)\n",
    "\n",
    "    result = board.result()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Game over. Result:\", result)\n",
    "\n",
    "    return result\n",
    "\n",
    "def run_multiple_games(white_chess_model, black_chess_model, num_games, num_simulations=100, num_threads=4, time_per_move=2):\n",
    "    game_results = []\n",
    "    white_score = 0\n",
    "    black_score = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = [executor.submit(play_game, i, num_games, white_chess_model, black_chess_model, num_simulations, i == 0, time_per_move) for i in range(num_games)]\n",
    "\n",
    "        completed_games = 0\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            result = future.result()\n",
    "            game_results.append(result)\n",
    "\n",
    "            if result == \"1-0\":\n",
    "                white_score += 1\n",
    "            elif result == \"0-1\":\n",
    "                black_score += 1\n",
    "\n",
    "            print(f\"Game {completed_games + 1} out of {num_games}\")\n",
    "            print(f\"White score: {white_score}, Black score: {black_score}\")\n",
    "\n",
    "            completed_games += 1\n",
    "            games_left = num_games - completed_games\n",
    "            elapsed_time = time.time() - start_time\n",
    "            avg_time_per_game = elapsed_time / completed_games if completed_games > 0 else 0\n",
    "            print(f\"Elapsed time: {elapsed_time:.2f}s, Avg time per game: {avg_time_per_game:.2f}s\")\n",
    "\n",
    "    return game_results\n",
    "\n",
    "num_games = 50\n",
    "game_results = run_multiple_games(white_chess_model, black_chess_model, num_games, num_simulations=100, num_threads=4, time_per_move=2)\n",
    "\n",
    "def print_game_results(game_results):\n",
    "    for i, result in enumerate(game_results):\n",
    "        print(f\"Game {i+1}: {result}\")\n",
    "\n",
    "print_game_results(game_results)\n",
    "\n",
    "white_chess_model.save_weights(\"weights/white_chess_model_weights.h5\")\n",
    "black_chess_model.save_weights(\"weights/black_chess_model_weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
